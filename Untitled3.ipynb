{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "523ace3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "import harmony\n",
    "import numpy as np\n",
    "from harmony.schemas.requests.text import Instrument, Question\n",
    "\n",
    "import evaluation_helper\n",
    "\n",
    "with open(\"10_tensorflow_js_vectors.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    question_to_vector = json.loads(f.read())\n",
    "\n",
    "\n",
    "def convert_texts_to_vector(texts):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        if text in question_to_vector:\n",
    "            vec_str = question_to_vector[text]\n",
    "            vec_str = re.sub(r'.+=\\s+\\\\*\\s*', '', vec_str)\n",
    "            vec = json.loads(vec_str)\n",
    "        else:\n",
    "            vec = [0.001] * 512 \n",
    "        vectors.append(np.asarray(vec))\n",
    "    return np.asarray(vectors)\n",
    "\n",
    "\n",
    "re_tokeniser = re.compile(r'([a-z]+)')\n",
    "\n",
    "for input_file, data in evaluation_helper.get_datasets():\n",
    "    all_questions = list(sorted(set(data.text_1).union(set(data.text_2))))\n",
    "    question_text_to_idx = dict([b, a] for a, b in enumerate(all_questions))\n",
    "    questions = []\n",
    "    for idx, question_text in enumerate(all_questions):\n",
    "        questions.append(Question(question_text=question_text, question_no=f\"{idx}\"))\n",
    "    instrument = Instrument(questions=questions)\n",
    "    questions, similarity, query_similarity, new_vectors_dict = harmony.match_instruments_with_function([instrument],\n",
    "                                                                                                        None,\n",
    "                                                                                                        convert_texts_to_vector)\n",
    "    preds = [0] * len(data)\n",
    "    for idx in range(len(data)):\n",
    "        text_1 = data.text_1.iloc[idx]\n",
    "        text_2 = data.text_2.iloc[idx]\n",
    "        idx_1 = question_text_to_idx[text_1]\n",
    "        idx_2 = question_text_to_idx[text_2]\n",
    "        preds[idx] = np.abs(similarity[idx_1, idx_2])\n",
    "\n",
    "    data[\"y_pred\"] = preds\n",
    "    \n",
    "    print(data[\"y_pred\"].isna().sum())\n",
    "\n",
    "    evaluation_helper.save_results(input_file, data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
